self.conv の前
torch.Size([100, 1, 28, 28])　batch size=100で100 個のデータを使用し、チャネル数 1、28 × 28 ピクセルであるから
self.relu の前
torch.Size([100, 6, 26, 26])　畳み込みの出力チャネル数が6なので第2引数は6，カーネル (フィルタ) サイズ H = 3，ストライド 1，パディングサイズ０を画像サイズの式に当てはめると,  畳み込み後の画像サイズは(28+0-3)/1 +1=26．
self.maxpooling の前
torch.Size([100, 6, 26, 26]) ReLU 活性化関数を通してもチャネル数や画像サイズは変化しない．
self.flatten の前
torch.Size([100, 6, 13, 13])　カーネル (フィルタ) サイズ H = ２，ストライド ２を画像サイズの式に当てはめると,  プーリング後の画像サイズは(26+0-2)/2 +1=13．
self.linear の前
torch.Size([100, 1014])　2 次元の画像を 1 次元ベクトルに変換する．ベクトルのサイズは6×13×13=1014
return logits の前
torch.Size([100, 10])　線形層 (出力10次元)を通してクラス分類されるのでサイズは10になる．

ク ロ ス エ ン ト ロ ピ ー 損 失

92.9 93.4  93.5 93.8dropoutさなし 94.0-64 94.3-32dropなし